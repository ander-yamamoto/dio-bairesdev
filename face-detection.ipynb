{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7XZW/jLBZ0AXEjGH8monu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ander-yamamoto/dio-bairesdev/blob/main/face-detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1Vjrj_mAQfYe",
        "outputId": "82fa367b-8570-4f44-e885-558504836408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting simple-image-download\n",
            "  Downloading simple_image_download-0.5-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from simple-image-download) (2.32.4)\n",
            "INFO: pip is looking at multiple versions of simple-image-download to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading simple_image_download-0.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading simple_image_download-0.2-py3-none-any.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->simple-image-download) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->simple-image-download) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->simple-image-download) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->simple-image-download) (2025.8.3)\n",
            "Downloading simple_image_download-0.2-py3-none-any.whl (3.8 kB)\n",
            "Installing collected packages: simple-image-download\n",
            "Successfully installed simple-image-download-0.2\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# 1. Imports e Configurações\n",
        "# =========================================\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "\n",
        "!pip install simple-image-download tqdm\n",
        "\n",
        "from simple_image_download import simple_image_download as simp\n",
        "from tqdm import tqdm\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 2. Função para baixar imagens\n",
        "# =========================================\n",
        "def download_with_progress(group, query, num_images):\n",
        "    downloader = simp.simple_image_download()\n",
        "    links = downloader.urls(query, num_images)  # pega URLs sem baixar ainda\n",
        "\n",
        "    save_dir = os.path.join(group, query)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for url in tqdm(links, desc=f\"Baixando {query}\"):\n",
        "        try:\n",
        "            img_data = requests.get(url, timeout=5).content\n",
        "            file_name = os.path.join(save_dir, os.path.basename(url.split(\"?\")[0]))\n",
        "            with open(file_name, \"wb\") as f:\n",
        "                f.write(img_data)\n",
        "        except:\n",
        "            pass  # ignora erros"
      ],
      "metadata": {
        "id": "PsByyD-1hnz-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 3. Baixar Dataset\n",
        "# =========================================\n",
        "\n",
        "group = \"Friends\"\n",
        "category=[\"Ross\", \"Chandler\", \"Joey\", \"Phoebe\", \"Monica\", \"Rachel\"]\n",
        "\n",
        "\n",
        "for cat in category:\n",
        "  if not os.path.exists(os.path.join(group, cat)):\n",
        "    download_with_progress(group, cat, 20)\n",
        "\n",
        "  else:\n",
        "    print(f\"Banco de imagens de {cat} já existe. Pulando download.\")\n",
        "\n",
        "# Listar categorias existentes\n",
        "\n",
        "categories = [\n",
        "    os.path.join(group, c)\n",
        "    for c in os.listdir(group)\n",
        "    if os.path.isdir(os.path.join(group, c))\n",
        "]\n",
        "print(\"Categorias:\", categories)"
      ],
      "metadata": {
        "id": "e3QUSi4Xhu_t",
        "outputId": "5f1451d2-bc96-4d4d-ce42-5701f631c99c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Baixando Ross: 100%|██████████| 20/20 [00:04<00:00,  4.21it/s]\n",
            "Baixando Chandler: 100%|██████████| 20/20 [00:03<00:00,  5.13it/s]\n",
            "Baixando Joey: 100%|██████████| 20/20 [00:02<00:00,  8.61it/s]\n",
            "Baixando Phoebe: 100%|██████████| 20/20 [00:04<00:00,  4.14it/s]\n",
            "Baixando Monica: 100%|██████████| 20/20 [00:05<00:00,  3.77it/s]\n",
            "Baixando Rachel: 100%|██████████| 20/20 [00:02<00:00,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorias: ['Friends/Joey', 'Friends/Ross', 'Friends/Phoebe', 'Friends/Rachel', 'Friends/Chandler', 'Friends/Monica']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install MTCNN\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from mtcnn import MTCNN\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Running on device: {device}')\n"
      ],
      "metadata": {
        "id": "UOAtVYlokbSF",
        "outputId": "c91ede34-1936-4d46-b7d4-0badd4afe6b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MTCNN\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from MTCNN) (1.5.1)\n",
            "Collecting lz4>=4.3.3 (from MTCNN)\n",
            "  Downloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, MTCNN\n",
            "Successfully installed MTCNN-1.0.0 lz4-4.4.4\n",
            "Running on device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_face_and_save(path, new_path=None, model=MTCNN, transformer=None, params=None):\n",
        "    \"\"\"\n",
        "    Detect face on each image, crop them and save to \"new_path\"\n",
        "    :param str path: path with images will be passed to  datasets.ImageFolder\n",
        "    :param str new_path: path to locate new \"aligned\" images, if new_path is None\n",
        "                     then new_path will be path + \"_cropped\"\n",
        "    :param model: model to detect faces, default MTCNN\n",
        "    :param transformer: transformer object will be passed to ImageFolder\n",
        "    :param params: parameters of MTCNN model\n",
        "    \"\"\"\n",
        "    if not new_path:\n",
        "        new_path = path + '_cropped'\n",
        "\n",
        "    # it is default parameters for MTCNN\n",
        "    if not params:\n",
        "        params = {\n",
        "            'image_size': 160, 'margin': 0,\n",
        "            'min_face_size': 10, 'thresholds': [0.6, 0.7, 0.7],\n",
        "            'factor': 0.709, 'post_process': False, 'device': device\n",
        "            }\n",
        "\n",
        "    model = model(**params)\n",
        "\n",
        "    if not transformer:\n",
        "        transformer = transforms.Lambda(\n",
        "            lambd=lambda x: x.resize((1280, 1280)) if (np.array(x) > 2000).all() else x\n",
        "        )\n",
        "    # for convenience we will use ImageFolder instead of getting Image objects by file paths\n",
        "    dataset = datasets.ImageFolder(path, transform=transformer)\n",
        "    dataset.samples = [(p, p.replace(path, new_path)) for p, _ in dataset.samples]\n",
        "\n",
        "    # batch size 1 as long as we havent exact image size and MTCNN will raise an error\n",
        "    loader = DataLoader(dataset, batch_size=1, collate_fn=training.collate_pil)\n",
        "    for i, (x, y) in enumerate(tqdm.tqdm(loader)):\n",
        "        model(x, save_path=y)\n",
        "\n",
        "    # spare some memory\n",
        "    del model, loader, dataset"
      ],
      "metadata": {
        "id": "qeOwV4RGlzAl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop_face_and_save(group)"
      ],
      "metadata": {
        "id": "eKsKBfkNm_7D",
        "outputId": "e018032c-fa81-4640-fdce-992d270c8dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "MTCNN.__init__() got an unexpected keyword argument 'image_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3460454982.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrop_face_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-195515212.py\u001b[0m in \u001b[0;36mcrop_face_and_save\u001b[0;34m(path, new_path, model, transformer, params)\u001b[0m\n\u001b[1;32m     20\u001b[0m             }\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MTCNN.__init__() got an unexpected keyword argument 'image_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=MTCNN\n",
        "path = group\n",
        "new_path = f'{group}__cropped'\n",
        "\n",
        "transformer = transforms.Lambda(\n",
        "            lambd=lambda x: x.resize((1280, 1280)) if (np.array(x) > 2000).all() else x\n",
        "        )\n",
        "dataset = datasets.ImageFolder(path, transform=transformer)\n",
        "dataset.samples = [(p, p.replace(path, new_path)) for p, _ in dataset.samples]\n",
        "loader = DataLoader(dataset, batch_size=1)\n",
        "for i, (x, y) in enumerate(tqdm(np.array(loader))):\n",
        "  model(x, save_path=y)"
      ],
      "metadata": {
        "id": "PdlcgKXMuEWZ",
        "outputId": "c574b120-e201-47c7-afe9-571eccef8e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "iteration over a 0-d array",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2110506471.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d array"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(path)"
      ],
      "metadata": {
        "id": "CxUncw6Hwf9m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.samples = [(p, p.replace(path, new_path)) for p, _ in dataset.samples]"
      ],
      "metadata": {
        "id": "JJLbIf89wiH2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "JbOp3lpYwi_w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loader)"
      ],
      "metadata": {
        "id": "xIC4af6ax5T4",
        "outputId": "3f8001ec-eca0-48e2-b95e-b4b335b49dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7da46dd19610>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qOq2Nmbx6Cs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}